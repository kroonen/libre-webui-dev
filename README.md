# Libre WebUI

A minimalist interface for local LLMs via Ollama.

![Rick Rubin Coding Wisdom](./rr.jpg)

*Like Rick Rubin strips music to its essence, Libre WebUI strips away UI complexity. Simple. Minimal. Effective.*

## Free & Open Source

100% free and open source software. No telemetry. No tracking. Your data stays on your hardware.

## Privacy First

Complete offline inference on your own hardware. No data leaves your machine unless you configure it to.

## Setup

```bash
# Option 1: Quick start
./start.sh

# Option 2: Manual
npm install
cd backend && npm install && cd ..
cd frontend && npm install && cd ..
npm run dev
```

## Ports
- Frontend: http://localhost:5173
- Backend: http://localhost:3001
- Ollama: http://localhost:11434

## Configuration

The app automatically generates configuration files on first run:

- `backend/preferences.json` - User preferences (default model, theme, system message)
- `backend/sessions.json` - Chat session data

These files are automatically created with sensible defaults and are excluded from version control to keep your personal settings private.

## Features

### ðŸš€ Core Features
- **Clean, minimal interface** - Rick Rubin-inspired simplicity
- **Light/Dark mode** - Comfortable viewing in any environment
- **Responsive design** - Works seamlessly on desktop, tablet, and mobile
- **Real-time chat** - Streaming responses with WebSocket integration
- **Fully private** - Offline inference on your own hardware
- **Zero telemetry** - No tracking, no data collection

### ðŸ¤– Complete Ollama Integration

All Ollama API endpoints are integrated and ready to use:

#### Chat & Generation
- âœ… **Chat Completion** - Full conversation support with history
- âœ… **Text Generation** - Single-turn completion with advanced options
- âœ… **Streaming Responses** - Real-time response generation
- âœ… **Multimodal Support** - Image input for vision models (llava, etc.)
- âœ… **Structured Outputs** - JSON schema validation and formatting
- âœ… **Tool Calling** - Function calling for enhanced capabilities

#### Model Management
- âœ… **List Models** - Browse all locally installed models
- âœ… **Pull Models** - Download from Ollama library with progress tracking
- âœ… **Delete Models** - Remove unused models to free space
- âœ… **Model Information** - Detailed specs, capabilities, and metadata
- âœ… **Create Models** - Build custom models from existing ones
- âœ… **Copy Models** - Duplicate models with different configurations
- âœ… **Push Models** - Upload custom models to share
- âœ… **Running Models** - View active models and memory usage

#### Advanced Features
- âœ… **Embeddings** - Generate text embeddings for semantic search
- âœ… **Blob Management** - Handle binary data for model creation
- âœ… **Version Detection** - Check Ollama server version
- âœ… **Health Monitoring** - Service status and connectivity checks

### ðŸŽ¯ UI Components
- **Model Manager** - Comprehensive model management interface
- **Chat Interface** - Intuitive conversation experience
- **Settings Panel** - Customizable preferences and options
- **Theme Toggle** - Seamless light/dark mode switching

### ðŸ”§ Developer Features
- **TypeScript** - Full type safety throughout the stack
- **REST API** - Traditional HTTP endpoints for all features
- **WebSocket** - Real-time bidirectional communication
- **Modular Architecture** - Clean separation of concerns
- **Comprehensive Documentation** - Detailed API and integration guides

## Architecture

```
libre-webui-dev/
â”œâ”€â”€ frontend/           # React + TypeScript + Tailwind CSS
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/ # Reusable UI components
â”‚   â”‚   â”œâ”€â”€ hooks/      # Custom React hooks
â”‚   â”‚   â”œâ”€â”€ store/      # State management (Zustand)
â”‚   â”‚   â”œâ”€â”€ utils/      # API clients and utilities
â”‚   â”‚   â””â”€â”€ types/      # TypeScript type definitions
â”œâ”€â”€ backend/            # Node.js + Express + TypeScript
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ routes/     # API route handlers
â”‚   â”‚   â”œâ”€â”€ services/   # Business logic and Ollama integration
â”‚   â”‚   â”œâ”€â”€ types/      # Shared type definitions
â”‚   â”‚   â””â”€â”€ middleware/ # Express middleware
â””â”€â”€ docs/              # Documentation and guides
```

## API Documentation

See [OLLAMA_INTEGRATION.md](./OLLAMA_INTEGRATION.md) for complete API documentation and usage examples.

Quick API examples:

```typescript
// Chat with streaming
const stream = chatApi.generateChatStreamResponse(sessionId, 'Hello!');
stream.subscribe(
  (chunk) => console.log('Received:', chunk),
  (error) => console.error('Error:', error),
  () => console.log('Complete')
);

// Model management
const models = await ollamaApi.getModels();
await ollamaApi.pullModel('llama3.2');

// Generate embeddings
const embeddings = await ollamaApi.generateEmbeddings({
  model: 'all-minilm',
  input: ['Text to embed']
});
```

## License
MIT
